---
title: "Exploring the Risk of Dreissenid Invasion in USACE Reservoirs"
author: "Todd Swannack, Iris Foxfoot, Kiara Cushway"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: '3'
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
  word_document:
    toc: true
    toc_depth: '3'
toc-title: Table of contents
sansfont: Calibri
---

# Purpose
This document summarizes the exploratory analysis we have conducted so far to assess and predict Dreissenid (*i.e.*, *Dreissena polymorpha* and *Dreissena rostriformis bugensis*) invasion in USACE reservoirs.

# Data exploration

## Data description
A description of the datasets used can be found below:

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)

## Load necessary packages
library(tidyr)
library(randomForest)
library(ROCR)
library(mlr)
library(dplyr)
library(FactoMineR)
library(factoextra)
library(knitr)
library(kableExtra)
library(ggplot2)
library(stringr)
library(caret)
library(sf) 
library(maps)
library(corrplot)

## Set seed to ensure consistent results
set.seed(123)
```

DATA OVERVIEW:

The data contained in these files were generated from multiple sources:
- USACE reservoir GIS data was sourced from a shapefile downloaded from https://geospatial-usace.opendata.arcgis.com/datasets/03e322d7e89b48a9b48e9c3f4bcaf29e/explore
- recreational visitor information was provided by The U.S. Army Corps of Engineers Institute for Water Resources.
- Dreissenid presenece/absence data was derived from USGS NAS data downloaded from https://nas.er.usgs.gov/queries/CollectionInfo.aspx?SpeciesID=3118
- Land use data was sourced from the NLCD land cover for 2021 downloaded from https://www.mrlc.gov/data?f%5B0%5D=category%3ALand%20Cover and USACE reservoir shapefiles.
- Surface geology data was generated using USGS surficial geology data downloaded from https://pubs.usgs.gov/ds/425/ and USACE reservoir shapefiles.
- Water hardness and pH data were interpolated for the conterminous US by the EPA and was obtained at: https://www.arcgis.com/home/item.html?id=ec9fe618d7e74c5ca68667b1c8d6e9bc and https://www.arcgis.com/home/item.html?id=bdc5b9ca9bfc454d8af22912ba150035.
- Climate data was sourced from PRISM 30 year (1990-2020) normal climate data, which was downloaded using the prism R package. For information on PRISM data see https://prism.oregonstate.edu/.
- Normalized Difference Chlorophyll Index (NDCI) data was derived from sentinel 2 imagery. Processed and downloaded from google earth engine.


Total records used in analysis: 352  



NOTES ABOUT CHANGES TO USACE RESERVOIRS SHAPEFILE:

1. There are two Sardis Lakes (Vicksburg and Tulsa districts), which have been renamed Sardis Lake Vicksburg and Sardis Lake Tulsa to distinguish them from one another. 
2. Aberdeen Lake, Columbus Lake, R.E. Bob Woodruff Lake, William Dannelly Reservoir, Bay Springs Lake, Tennessee-Tombigbee Waterway at Fulton, Tennessee-Tombigbee Waterway at G.V. Montogmery, and Tennessee-Tombigbee Waterway at Glover Wilkins in the Mobile District had repeated records that were a subset of the whole lake, and these were deleted for analysis.
3. Water Conservation Area 1, 2A, 3A, 2B, and 3B were merged into a single record: "Water Conservation Area Combined"
4. Arkport Reservoir was deleted because it is a dry dam that is only impounded after rain
5. Jadwin Reservoir was deleted because it is a dry dam that is only impounded after rain
6. Candy Lake Reservoir was deleted because it was never built according to USACE records
7. Hulah Lake, Lake Barkley, and Lake Shelbyville had extra disconnected fragments that were deleted
8. Southern disconnected portion of Lake Merrisach was deleted
9. Lake Merrisach, Arkansas River Pool 2, and Arkansas Post Canal Reservoir were merged into a single record because they appeared to be entirely connected
10. The section of Robert S. Kerr Reservoir between Robert S. Kerr Lock and Dam and W.D. Mayo Lock and Dam was deleted
11. Arkansas River Pool 13 was combined with the portion of Robert S. Kerr Reservoir that stretches upstream to W.D. Mayo Lock and Dam
12. 50 reservoirs were removed because they were dry according to USACE record (Dry=Yes in attribute table)



HARDNESS AND pH COLUMNS:

1. Water hardness and pH data were interpolated for the conterminous US by the EPA and was obtained at: https://www.arcgis.com/home/item.html?id=ec9fe618d7e74c5ca68667b1c8d6e9bc and https://www.arcgis.com/home/item.html?id=bdc5b9ca9bfc454d8af22912ba150035. Data was generated by clipping the shapefile to the extent of the USACE reservoirs shapefile and converting to a raster, then using tabulate area to determine hardness class of each reservoir
2. hardness_range includes the range of hardness values occurring in the reservoir based on the hardness shapefile. If multiple classes occurred in the reservoir, the range was expanded to include all of them



COLUMNS PERC_OPEN_WATER_25MI - PERC_HERBACEOUSWETLAND_50MI:

This data was generated using NLCD land cover for 2021 downloaded from https://www.mrlc.gov/data?f%5B0%5D=category%3ALand%20Cover and USACE reservoir shapefiles.

In ArcGIS Pro, 25 mile and 50 mile buffers were created around each USACE reservoir, and the number of pixels belonging to each land use type was counted for each buffer using the "Tabulate Area" tool. The percent of each buffer representing each land use type was then calculated by dividing the number of pixels of each land use type by the total number of pixels in the buffer. Note that not all percentages add up to 100% because some buffers extended into Canada or the ocean, outside of the coverage of NLCD data (hence, pixels we considered "unclassed" and were excluded from analysis).



SURFICIAL GEOLOGY:

This data was generated using USGS surficial geology data downloaded from https://pubs.usgs.gov/ds/425/ and USACE reservoir shapefiles. In ArcGIS Pro, 25 mile buffers were created around each USACE reservoir, and the number of pixels belonging to each surficial geology type was counted for each buffer using the "Tabulate Area" tool. The percent of each buffer representing each land use type was then calculated by dividing the number of pixels of each land use type by the total number of pixels in the buffer.



CLIMATE DATA:

Climate data was extracted from PRISM 30 year (1990-2020) normal climate data, which was downloaded using the prism R package. For information on PRISM data see https://prism.oregonstate.edu/.

to produce this data, the center point of each reservior was found. Using this center point, values for "ppt" (precipitation), "tmean" (mean temperature), "tmin" (min temperature), "tmax" (max temperature), "tdmean" (mean dew point temp) "vpdmin" (minimum vapor deficit), and "vpdmax" (max vapor deficit) were extracted from the PRISM 30 year (1990-2020) year normal 800m resolution raster cells. These data were then condensed into seasonal totals (for precipitaiton), seasonal means (for temperature, dew point-called dewp), seasonal mins (for temperature and vapor pressure deficit --called vpd), and seasonal maxs (for temperature and vapor pressure deficit--called vpd)

temperature is in Celsius, precipitation is in millimeters, and vapor pressure deficit is in hectopascals.

seasons are as follows:
- winter = dec, jan, feb
- spring = mar, apr, may
- summer = jun, jul, aug
- fall = sep, oct, nov



NDCI DATA:

Sentinel-2 data acquisition was done using google earth engine. We used Sentinel 2: Level-2A orthorectified atmospherically corrected surface reflectance from Jan 1st 2023 to Jan 1st 2024. First, the USACE reservoir shapefile was uploaded to google earth engine as an asset. It was then imported and simplified to be accurate within 100m using the simplify function to reduce the complexity of the object. Within each simplified reservoir, we then selected pixels that were classified as water in sentinel-2 L2A's Scene Classification (SCL) image. Water pixels are designated a value of 6. This was done to remove potential clouds, ice, snow, and land pixels from the dataset. Then we calculated the mean of all bands of interest across all water pixels within the simplified reservoir. These values were then exported from google earth engine. 

Then, using R we calculated Normalized Difference Chlorophyll Index (NDCI) from Mishra & Mishra 2012. The NDCI output ranges from -1 to 1, smaller values likely have less chlorophyll-a while higher values likely have an increased concentration of chlorophyll-a. Though the NDCI was developed for coastal and estuary waters, it has also been successfully used for North American reservoirs (see Kislik et al., 2022). NDCI was then aggregated into seasonal minimums, means, and maximums for each reservoir.

When using sentinel 2 data, the formula for NDCI is

$(B5 - B4)/(B5 + B4)$

Where B5 is red edge 1 and B4 is red.

seasons are as follows:
- winter = dec, jan, feb
- spring = mar, apr, may
- summer = jun, jul, aug
- fall = sep, oct, nov

COLUMNS:

- name: Name of reservoir (from USACE shapefiles)

- district: District in charge of reservoir (from USACE shapefiles)

- dist_sym: District symbol (from USACE shapefiles)

- division: Division in charge of reservoir (from USACE shapefiles)
- div_sym: Division symbol (from USACE shapefiles)
- dry: Whether the reservoir is dry (from USACE shapefiles)
- connectivity: Type of barrier between reservoir and other reservoir polygons immediately adjacent (NOTE: this only includes reservoirs where polygons are immediately adjacent, not reservoirs that may be relatively connected according to imagery)
- dam_name: Name of dam (from USACE shapefiles)
- dist_to_infest_km: Distance to nearest ZQM presence record from NAS data in km, calculated using "Generate Near Table" in ArcGIS Pro using the geodesic measurement method. If the near distance was 0, a reservoir was infested, and the next closest record was selected. To account for measurement/GPS error, all records within 100m (0.1km) of a reservoir were checked visually. If a record was not clearly in a different waterbody, the record was considered within the range of GPS error and the next furthest record was selected until the record was either >100m away from the reservoir or clearly occupying another waterbody (e.g., above a dam)
- surface_area_km: Surface area of reservoir (km); calculated using "Calculate Geometry" tool in ArcGIS Pro
- connectivity: Type of connection between adjacent reservoirs (None, Lock and Dam, Dam)
- num_connections: Number of direct connections (e.g., lock and dam) a reservoir has to adjacent reservoirs
- perc_open_water_25mi: percent land cover within 25 miles of reservoir consisting of open water
- perc_perennial_snowice_25mi: percent land cover within 25 miles of reservoir consisting of perennial snow and ice
- perce_dev_openspace_25mi: percent land cover within 25 miles of reservoir consisting of developed open space
- perc_dev_lowintensity_25mi: percent land cover within 25 miles of reservoir consisting of low intensity development
- perc_dev_medintensity_25mi: percent land cover within 25 miles of reservoir consisting of medium intensity development
- perc_dev_highintensity_25mi: percent land cover within 25 miles of reservoir consisting of high intensity development
- perc_barren_25mi: percent land cover within 25 miles of reservoir consisting of barren land
- perc_forest_25mi: percent land cover within 25 miles of reservoir consisting of deciduous, evergreen, or mixed forest
- perc_shrubscrub_25mi: percent land cover within 25 miles of reservoir consisting of shrub and scrub
- perc_herbaceous_25mi: percent land cover within 25 miles of reservoir consisting of herbaceous land
- perc_haypasture_25mi: percent land cover within 25 miles of reservoir consisting of hay and pastureland
- perc_crops_25mi: percent land cover within 25 miles of reservoir consisting of crops
- perc_wetland_25mi: percent land cover within 25 miles of reservoir consisting of woody or herbaceous wetlands
- perc_open_water_50mi: percent land cover within 50 miles of reservoir consisting of open water
- perc_perennial_snowice_50mi: percent land cover within 50 miles of reservoir consisting of perennial snow and ice
- perce_dev_openspace_50mi: percent land cover within 50 miles of reservoir consisting of developed open space
- perc_dev_lowintensity_50mi: percent land cover within 50 miles of reservoir consisting of low intensity development
- perc_dev_medintensity_50mi: percent land cover within 50 miles of reservoir consisting of medium intensity development
- perc_dev_highintensity_50mi: percent land cover within 50 miles of reservoir consisting of high intensity development
- perc_barren_50mi: percent land cover within 50 miles of reservoir consisting of barren land
- perc_forest_50mi: percent land cover within 50 miles of reservoir consisting of deciduous, evergreen, or mixed forest
- perc_shrubscrub_50mi: percent land cover within 50 miles of reservoir consisting of shrub and scrub
- perc_herbaceous_50mi: percent land cover within 50 miles of reservoir consisting of herbaceous vegetation
- perc_haypasture_50mi: percent land cover within 50 miles of reservoir consisting of hay and pastureland
- perc_crops_50mi: percent land cover within 50 miles of reservoir consisting of cropland
- perc_wetland_50mi: percent land cover within 50 miles of reservoir consisting of woody or herbaceous wetland
- mean_slope: average slope of reservoir, calculated using PRISM slope raster and zonal statistics as table with reservoirs as zones. A few reservoirs were calculated by hand because zonal statistics did not work for them
- mean_elev_m: average elevation of each reservoir (in m), calculated using PRISM 800m elevation raster and zonal statistics as table with reservoirs as zones. A few reservoirs were calculated by hand because zonal statistics did not work for them
- perc_CaO_25mi:  % lithological calcium oxide (CaO) content in surface or near surface geology in a 25 mile buffer around reservoir; obtained from https://www.sciencebase.gov/catalog/item/53543d10e4b0bab7f98ce7e0
- perc_alluvial_25mi: % surficial geology in a 25 mile buffer with a major classification of "alluvial" (UNIT CODE begins with 0)
- perc_eolian_25mi:% surficial geology in a 25 mile buffer with a major classification of "eolian" (UNIT CODE begins with 3)	
- perc_glacial_glaciofluvial_25mi: % surficial geology in a 25 mile buffer with a major classification of "glacial till and glaciofluvial" (UNIT CODE begins with 4)
- perc_lacustrine_25mi	colluvial_25mi: % surficial geology in a 25 mile buffer with a major classification of "colluvial" (UNIT CODE begins with 6)
- perc_organic_rich_25mi: % surficial geology in a 25 mile buffer with a major classification of "organic-rich" (UNIT CODE begins with 7)	
- perc_proglacial_25mi:% surficial geology in a 25 mile buffer with a major classification of "proglacial" (UNIT CODE begins with 8)
- perc_resid_volcanic_art_wat_25mi: % surficial geology in a 25 mile buffer with a major classification of "residual, volcanic, artificial, and water" (UNIT CODE begins with 9)
- hardness_range: range of hardness values in milligrams per liter of CaCO3 observed based on EPA shapefile
- min_hardness: minimum hardness value in milligrams per liter of CaCO3 observed in reservoir based on EPA shapefile
- max_hardness: maximum hardness value in milligrams per liter of CaCO3 observed in reservoir based on EPA shapefile
- pH_range: range of pH values observed in reservoir based on interpolated shapefile from EPA
- pH_min: minimum pH observed near reservoir based on interpolated shapefile from EPA
- pH_max: maximum pH observed near reservoir based on interpolated shapefile from EPA
- winter_total_precip: Winter total precip (mm), calculated from PRISM 30 yr normal dataset.             
- spring_total_precip: Spring total precip (mm), calculated from PRISM 30 yr normal dataset.             
- summer_total_precip: Summer total precip (mm), calculated from PRISM 30 yr normal dataset.            
- fall_total_precip: Fall total precip (mm), calculated from PRISM 30 yr normal dataset.              
- winter_mean_temp: Winter mean air temperature (C), calculated from PRISM 30 yr normal dataset.              
- spring_mean_temp: Spring mean air temperature (C), calculated from PRISM 30 yr normal dataset.                
- summer_mean_temp: Summer mean air temperature (C), calculated from PRISM 30 yr normal dataset.               
- fall_mean_temp: Fall mean air temperature (C), calculated from PRISM 30 yr normal dataset.                 
- winter_min_temp: Winter mean daily minimum air temperature (C), calculated from PRISM 30 yr normal dataset.               
- spring_min_temp: Spring mean daily minimum air temperature (C), calculated from PRISM 30 yr normal dataset.               
- summer_min_temp: Summer mean daily minimum air temperature (C), calculated from PRISM 30 yr normal dataset.                
- fall_min_temp: Fall mean daily minimum air temperature (C), calculated from PRISM 30 yr normal dataset.                  
- winter_max_temp: Winter mean daily maximum air temperature (C), calculated from PRISM 30 yr normal dataset.                
- spring_max_temp: Spring mean daily maximum air temperature (C), calculated from PRISM 30 yr normal dataset.                
- summer_max_temp: Summer mean daily maximum air temperature (C), calculated from PRISM 30 yr normal dataset.                
- fall_max_temp: Fall mean daily maximum air temperature (C), calculated from PRISM 30 yr normal dataset.                  
- winter_mean_dewp: Winter mean daily dew point (C), calculated from PRISM 30 yr normal dataset.               
- spring_mean_dewp: Spring mean daily dew point (C), calculated from PRISM 30 yr normal dataset.               
- summer_mean_dewp: Summer mean daily dew point (C), calculated from PRISM 30 yr normal dataset.                
- fall_mean_dewp: Fall mean daily dew point (C), calculated from PRISM 30 yr normal dataset.                 
- winter_min_vpd: Winter mean daily minimum vapor pressure deficit (hectopascals), calculated from PRISM 30 yr normal dataset.                 
- spring_min_vpd: Spring mean daily minimum vapor pressure deficit (hectopascals), calculated from PRISM 30 yr normal dataset.                 
- summer_min_vpd: Summer mean daily minimum vapor pressure deficit (hectopascals), calculated from PRISM 30 yr normal dataset.                
- fall_min_vpd: Fall mean daily minimum vapor pressure deficit (hectopascals), calculated from PRISM 30 yr normal dataset.                 
- winter_max_vpd: Winter mean daily maximum vapor pressure deficit (hectopascals), calculated from PRISM 30 yr normal dataset.               
- spring_max_vpd: Spring mean daily maximum vapor pressure deficit (hectopascals), calculated from PRISM 30 yr normal dataset.                 
- summer_max_vpd: Summer mean daily maximum vapor pressure deficit (hectopascals), calculated from PRISM 30 yr normal dataset.                 
- fall_max_vpd: Fall mean daily maximum vapor pressure deficit (hectopascals), calculated from PRISM 30 yr normal dataset.                    
- mean_ndci_fall: Fall mean Normalized Difference Chlorophyll Index.
- mean_ndci_spring: Spring mean Normalized Difference Chlorophyll Index.      
- mean_ndci_summer: Summer mean Normalized Difference Chlorophyll Index.      
- mean_ndci_winter: Winter mean Normalized Difference Chlorophyll Index.      
- min_ndci_fall: Fall minimum Normalized Difference Chlorophyll Index.         
- min_ndci_spring: Spring minimum Normalized Difference Chlorophyll Index.     
- min_ndci_summer: Summer minimum Normalized Difference Chlorophyll Index.    
- min_ndci_winter: Winter minimum Normalized Difference Chlorophyll Index.    
- max_ndci_fall: Fall maximum Normalized Difference Chlorophyll Index.         
- max_ndci_spring: Spring maximum Normalized Difference Chlorophyll Index.     
- max_ndci_summer: Summer maximum Normalized Difference Chlorophyll Index.     
- max_ndci_winter: Winter maximum Normalized Difference Chlorophyll Index.
- mean_total_visits: The average annual number of recreational visitors from 2014-2024.
- min_Ca:
- max_Ca:
- avg_Ca:
- min_pH:
- max_pH:
- avg_pH:
- infest_status: Whether or not a reservoir is infested by ZQM or not according to NAS data (determined based on dist_to_infest_km=0 or <100m and not clearly in some other water body); 0=uninfested, 1=infested


## Infestation patterns in USACE reservoirs

Approximately 24% of the 352 reservoirs we examined have recorded Dreissenid presences according to USGS Non-indigenous Aquatic Species (NAS) data (Benson et al. 2024). The remaining 76% are currently considered un-infested (Table 1). Note that NAS data provides information on reports of Dreissenid presence only, and presence does not necessarily imply successful establishment. Absences are not reported. Note also that the absence of positive records in a state (e.g., Michigan) does not imply that Dreissenids are not present there, just that no Dreissenids have been recorded in USACE reservoirs within the state.

```{r warning=FALSE, message=FALSE}


## Get state data
state_map = map_data("state")

## Load USACE reservoir data
res_raw = read_sf("USACE_Reservoirs/USACE_Reservoirs_Final.shp") %>% 
  janitor::clean_names() %>% 
  sf::st_make_valid() 

## Get centers of lakes
res_center = st_centroid(res_raw) %>% 
  select(infest_sta, name) %>% 
  mutate(infest_status = as.factor(infest_sta))

## Plot data
ggplot() +
  geom_polygon(data = state_map, aes(x = long,y = lat,group = group), inherit.aes = F, 
     colour = 'black', fill = NA) +
  geom_sf(data = res_center, aes(color = infest_status)) +
  scale_color_manual(values = c("0" = "blue", "1" = "red"), 
                     labels = c("0" = "absent", "1" = "present"),
                     name = "Dreissenid Presence") +
  labs(title = "Dreissenid presence in USACE reservoirs") +
  theme_void()
```

**Figure 1.** Location of Dreissenid infested and un-infested USACE reservoirs (n=352). Infestation status was determined using USGS Non-indigenous Aquatic Species data (Benson et al. 2024).

<br> <br>

```{r warning=FALSE, message=FALSE}

## Bring in data
ZQM_data= read.csv("data/USACE_Reservoirs_Final.csv")

## Subset data to include variables of interest only
ZQM = ZQM_data[,9:length(ZQM_data)]


## Count infested versus non-infested reservoirs
infest = summarise(group_by(ZQM,infest_status),count = n(),status = NA)
## 84 infested
## 268 not infested

## Set infestation status for table
for (i in 1:nrow(infest)) {
  if (infest$infest_status[i] == 0){
    infest$status[i] = "Un-infested"
  } else{
      infest$status[i] = "Infested"
    }
}

## Create table
kable(infest[,c(3,2)],col.names = c("Infestation status","Number of reservoirs"),align = "c",
      caption = "Number of Dreissenid infested and un-infested USACE reservoirs (n=352). Infestation status was determined using USGS Non-indigenous Aquatic Species data (Benson et al. 2024).") %>% kable_styling() %>% row_spec(2, extra_css = "border-bottom: 1px solid;") %>% row_spec(0, bold = T, align = "c",extra_css = "border-bottom: 1px solid;")

```

## Environmental thresholds

We attempted to predict and assess Dreissenid infestation in USACE reservoirs using environmental data and assessed invasion risk based on discrete environmental thresholds that have been identified in the literature as facilitating or preventing Dreissenid invasion (Doll 1997; Sorba and Williamson 1997; Cohen and Weinstein 1998; Cohen 2005; Creamer et al., 2025). We used these environmental thresholds to define reservoir characteristics that may lead to low, moderate, or high risk of Dreissenid infestation (Table 2). Since not all literature reported the same thresholds, we chose the most conservative values such that we were more likely to overestimate than underestimate risk of infestation. For example, if one study defined low risk habitat as areas with a hardness < 45 mg/L and another as < 55 mg/L, we selected 45 mg/L as the maximum hardness describing low risk habitat, resulting in a wider moderate risk category.

Initially, we included maximum summer temperature in our risk assessment, but we found that the risk categories identified were not necessarily a good representation of invasion risk, as a higher proportion of moderate-risk reservoirs were already invaded by Dreissenids compared to high risk reservoirs. While maximum temperature is likely a factor that does limit Dreissenid range, the duration of high temperature events may be an important factor that was missing from our assessment. Since we have no information about how long maximum summer temperatures occurred, it is difficult to assess their effect on mussels, as Dreissenids may be able to survive short-term exposure to high temperatures but could have higher mortality during longer high temperature events (White et al., 2015). Hence, we removed maximum temperature from our risk assessment but included it in our statistical analyses investigating the relationship between environmental parameters and Dreissenid presence.


```{r warning=FALSE,message=FALSE,echo=FALSE}

## Bring in table of thresholds
threshold_defs = read.csv("data/env_thresholds.csv")

## Create formatted table to display thresholds
kable(threshold_defs,col.names = c("Metric", "Low risk", "Moderate risk", "High risk", "Reference"),align = c("l","c","c","c","l"),
      caption = "Descriptions of environmental characteristics used in this analysis identified as contributing to low, moderate, or high risk of Dreissenid invasion. Note that in some cases, limited categorical data representing ranges was available for variables.") %>% kable_styling(latex_options = "scale_down", font_size = 8) %>% row_spec(0, bold = T, extra_css = "border-bottom: 1px solid;") %>% row_spec(5, extra_css = "border-bottom: 1px solid;")

```

Using the data we compiled, we assigned each USACE reservoir as low, moderate, or high risk for each of the variables in Table 2 (Table 3). We then assessed how many reservoirs falling into each risk category were currently infested (Table 4, Figure 3) and assigned an overall risk for each reservoir by selecting the lowest risk category for any variable (Table 4, Table 5, Figure 3). Any reservoirs categorized as low risk for any of the variables were assigned a low overall risk, while reservoirs with no low risk variables and at least one moderate risk variable were assigned moderate risk. Reservoirs assigned high risk status for all variables were defined as having high overall risk.

```{r, message=FALSE, warning=FALSE}

## Bring in data
thresholds = read.csv("data/USACE_Reservoirs_Thresholds.csv")

## Assign risk categories based on environmental thresholds

## Loop through mean summer temperature to ID risk categories
for (i in 1:nrow(thresholds)) {
  if (thresholds$summer_mean_temp[i] < 15 | thresholds$summer_mean_temp[i] > 32) {
    thresholds$mean_sum_temp_threshold[i] = "Low"
  } else if ((thresholds$summer_mean_temp[i] >= 31 & thresholds$summer_mean_temp[i] <= 32)){
      thresholds$mean_sum_temp_threshold[i] = "Moderate"
    } else if (thresholds$summer_mean_temp[i] >= 15 | thresholds$summer_mean_temp[i] <= 31) {
      thresholds$mean_sum_temp_threshold[i] = "High"
    } else {
      thresholds$mean_sum_temp_threshold[i] = "Out of range"
  }
}


## Loop through pH to ID risk categories
for (i in 1:nrow(thresholds)) {
  if (thresholds$max_pH[i] < 6.8 | thresholds$max_pH[i] > 9.5) {
    thresholds$pH_threshold[i] = "Low"
  } else if ((thresholds$max_pH[i] >= 6.8 & thresholds$max_pH[i] < 7.4) | 
             (thresholds$max_pH[i] > 8.7 & thresholds$max_pH[i] <= 9.5)) {
      thresholds$pH_threshold[i] = "Moderate"
  } else if (thresholds$max_pH[i] >= 7.4 & thresholds$max_pH[i] <= 8.7) {
      thresholds$pH_threshold[i] = "High"
  } else {
      thresholds$pH_threshold[i] = "Out of range"
  }
}


## Loop through hardness to ID risk categories
for (i in 1:nrow(thresholds)) {
  if (thresholds$max_hardness[i] < 45) {
    thresholds$hardness_threshold[i] = "Low"
  } else if (thresholds$max_hardness[i] >= 45 & thresholds$max_hardness[i] <= 90) {
    thresholds$hardness_threshold[i] = "Moderate"
  } else if (thresholds$max_hardness[i] >= 90) {
    thresholds$hardness_threshold[i] = "High"
  } else {
      thresholds$hardness_threshold[i] = "Out of range"
  }
}

## Loop through calcium to ID risk categories
for (i in 1:nrow(thresholds)) {
  if (thresholds$max_Ca[i] < 9) {
    thresholds$calcium_threshold[i] = "Low"
  } else if (thresholds$max_Ca[i] >= 9 & thresholds$max_Ca[i] <= 15) {
    thresholds$calcium_threshold[i] = "Moderate"
  } else if (thresholds$max_Ca[i] > 15) {
    thresholds$calcium_threshold[i] = "High"
  } else {
      thresholds$calcium_threshold[i] = "Out of range"
  }
}

## Loop through distance to nearest infestation to ID risk categories
for (i in 1:nrow(thresholds)) {
  if(thresholds$dist_to_infest_km[i] > 125) {
    thresholds$dist_threshold_km[i] = "Low"
  } else if (thresholds$dist_to_infest_km[i] >= 51 & thresholds$dist_to_infest_km[i] <= 125) {
      thresholds$dist_threshold_km[i] = "Moderate"
  } else if (thresholds$dist_to_infest_km[i] < 51) {
      thresholds$dist_threshold_km[i] = "High"
  } else {
      thresholds$dist_threshold_km[i] = "Out of range"
  }
}


## Loop through risk categories to determine overall risk
for (i in 1:nrow(thresholds)) {
  if (sum(str_detect(thresholds[i,15:19], "Low")) > 0) {
    thresholds$overall_risk[i] = "Low"
  } else if ((sum(str_detect(thresholds[i,15:19], "Low")) == 0) & 
             (sum(str_detect(thresholds[i,15:19], "Moderate")) > 0)) {
      thresholds$overall_risk[i] = "Moderate"
  } else if (sum(str_detect(thresholds[i,15:19], "High")) == 5) {
     thresholds$overall_risk[i] = "High"
  } else {
    thresholds$overall_risk[i] = "ERROR"
  }
}

## Loop through risk categories to determine overall risk without considering distance to nearest infestation
for (i in 1:nrow(thresholds)) {
  if (sum(str_detect(thresholds[i,15:18], "Low")) > 0) {
    thresholds$overall_risk_nodist[i] = "Low"
  } else if ((sum(str_detect(thresholds[i,15:18], "Low")) == 0) & 
             (sum(str_detect(thresholds[i,15:18], "Moderate")) > 0)) {
      thresholds$overall_risk_nodist[i] = "Moderate"
  } else if (sum(str_detect(thresholds[i,15:18], "High")) == 4) {
     thresholds$overall_risk_nodist[i] = "High"
  } else {
    thresholds$overall_risk_nodist[i] = "ERROR"
  }
}


## Generate infestation status
for (i in 1:nrow(thresholds)) {
  if (thresholds$infest_status[i] == 1) {
    thresholds$infestation[i] = "Infested"
  } else {
    thresholds$infestation[i] = "Not infested"
  }
}

#save thresholds with lake names
#write.csv(thresholds, "risk_thresholds_per_res.csv")

counts=thresholds %>% group_by(overall_risk,overall_risk_nodist) %>% summarise(count = n())

###Risk table
kable(thresholds[,c(1,15:22)],col.names=c("Reservoir","Mean summer temp risk","pH risk","Hardness risk","Calcium risk","Distance risk","Overall risk", "Overall risk without distance","Infestation status"),align="l",
      caption = "Risk classifications for USACE reservoirs based on environmental thresholds known to influence Dreissenid survival.") %>% 
  kable_styling(latex_options = "scale_down", font_size = 8)%>% 
  column_spec(2:ncol(thresholds[,c(1,15:22)]), width = "50px") %>% 
  scroll_box(width = "1000px", height = "500px")%>% 
  row_spec(0, bold = T, align="l",
           extra_css = "border-bottom: 1px solid;") %>% 
  kableExtra::landscape()

```

<br> <br>

```{r}
## Bind threshold data to geo data
thresh_geo <- left_join(res_center, thresholds, join_by(name))

## Re-level factors
thresh_geo$overall_risk <- factor(thresh_geo$overall_risk, 
                                  levels = c("High", "Moderate", "Low"))

## plot data
ggplot() +
  geom_polygon(data = state_map, aes(x=long,y=lat,group=group), inherit.aes=F, 
     colour='black', fill=NA) +
  geom_sf(data = thresh_geo, aes(color = overall_risk)) +
  scale_color_manual(values = c("Low" = "#44AA99", "Moderate" = "#DDCC77", "High" = "#882255"),
                     name = "Risk of Dreissenid infestation") +
  labs(title = "Dreissenid invasion risk in USACE reservoirs") +
  theme_void()
```

**Figure 2.** Locations of low, moderate, and high risk reservoirs for dreissenid infestation. Risk was based on calcium levels, mean summer temperature, total water hardness, water pH, and distance to the nearest infestation

<br>
<br>

Since distance to infestation is likely to change over time as Dreissenids become established in new locations, we also assessed whether risk status changed if distance was not considered as a risk factor. Not considering distance resulted in 30 reservoirs with a low overall risk being elevated to high risk, and an additional 20 being elevated to moderate risk. Additionally, 58 reservoirs that were initially considered moderate risk based on distance to infestation were elevated to high risk.
<br>

```{r}
## Re-level variables
thresh_geo$overall_risk_nodist <- factor(thresh_geo$overall_risk_nodist, 
                                  levels = c("High", "Moderate", "Low"))

## Plot graph
ggplot() +
  geom_polygon(data = state_map, aes(x=long,y=lat,group=group), inherit.aes=F, 
     colour='black', fill=NA) +
  geom_sf(data = thresh_geo, aes(color = overall_risk_nodist)) +
  scale_color_manual(values = c("Low" = "#44AA99", "Moderate" = "#DDCC77", "High" = "#882255"),
                     name = "Risk of Dreissenid infestation") +
  labs(title = "Dreissenid invasion risk in USACE reservoirs without\nconsidering distance to nearest invasion") +
  theme_void()

```

**Figure 3.** Location of low, moderate, and high risk reservoirs for Dreissenid infestation when not considering distance to nearest infestation as a risk factor. Risk was based on mean summer temperature, total water hardness, calcium concentration, and pH. Low risk reservoirs are classified as such by potentially unsuitable water chemistry. One reservoir in Arizona is considered unsuitable because of summer temperatures.

<br> <br>

```{r warning=FALSE,message=FALSE}

## Examine how risk category for each variable relates to infestation status

## Mean temperature
mean_temp = thresholds %>% group_by(mean_sum_temp_threshold,infestation) %>% summarise(count = n()) %>%
  pivot_wider(names_from = mean_sum_temp_threshold, values_from = count) %>% mutate(var = "Mean temperature") %>% mutate(Moderate = NA)

## pH
pH = thresholds %>% group_by(pH_threshold,infestation) %>% summarise(count=n()) %>%
  pivot_wider(names_from = pH_threshold, values_from = count) %>% mutate(var = "pH")

## Hardness
hardness = thresholds %>% group_by(hardness_threshold,infestation) %>% summarise(count = n()) %>%
  pivot_wider(names_from = hardness_threshold, values_from = count) %>% mutate(var = "Hardness")

## Calcium
calcium = thresholds %>% group_by(calcium_threshold,infestation) %>% summarise(count = n()) %>%
  pivot_wider(names_from = calcium_threshold, values_from = count) %>% mutate(var = "Calcium")

## Distance
distance = thresholds %>% group_by(dist_threshold_km,infestation) %>% summarise(count=n()) %>%
  pivot_wider(names_from = dist_threshold_km, values_from = count) %>% mutate(var = "Distance")

## Combine into a single table
risk=rbind(mean_temp,pH,hardness,calcium,distance)

## Replace NAs with zeroes
risk$Moderate=risk$Moderate %>% replace_na(0)
risk$Low=risk$Low %>% replace_na(0)
risk$High=risk$High %>% replace_na(0)

## Re-arrange order of columns
risk=risk[,c(4,1,3,5,2)]

## Display results in table format
kable(risk,col.names = c("Environmental variable","Infestation status","Low Risk","Moderate Risk", "High Risk"),align = "c", caption = "Number of Dreissenid infested and un-infested reservoirs characterized as low, moderate, or high risk of invasion based on environmental characteristics.") %>% 
  kable_styling(latex_options = "scale_down", font_size = 8) %>% 
  collapse_rows(columns = 1,valign="top") %>% 
  row_spec(0, bold = T, align = "c",
           extra_css = "border-bottom: 1px solid;") %>%
  row_spec(10, extra_css = "border-bottom: 1px solid;") %>% 
  column_spec(1,extra_css = "border-bottom: 1px solid;") %>% 
  row_spec(c(2,4,6,8,10),extra_css = "border-bottom: 1px solid") %>% 
  scroll_box(width = "1000px", height = "500px")
```

<br> <br> <br>

```{r warning=FALSE, message=FALSE,fig.height=30,fig.width=45}

## Graph low, moderate, and high risk according to infested and uninfested

## Change data format to longer
risk_long=risk %>% pivot_longer(cols=c("Low","Moderate","High"),names_to = "Risk_level")

risk_long$order=c(1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3)

risk_long %>% ggplot(aes(fill=infestation,y=value,x=reorder(Risk_level,order)))+ geom_bar(position="dodge",stat="identity")+facet_wrap(~var,ncol=3,nrow=2)+labs(x="Risk level",y="Number of reservoirs")+ theme(text=element_text(size=50))+scale_fill_manual(values=c("navyblue","orchid"),name="Infestation status")

```

**Figure 4.** Number of Dreissenid infested and un-infested USACE reservoirs falling into each risk category (low, moderate, or high) for specified variables.

<br> <br>

```{r warning=FALSE, message=FALSE}

## Summarise percent of reservoirs in each risk category
overall_risk_pct=thresholds %>% group_by(overall_risk) %>% summarise(pct = round(n()/352*100,2)) %>% pivot_wider(names_from = overall_risk, values_from = pct)

overall_risk_pct = overall_risk_pct[,c(2,3,1)]

kable(overall_risk_pct,align = "c",col.names = c("Low risk (%)","Moderate risk (%)", "High risk (%)"), caption = "Percent of USACE reservoirs falling into each risk category for Dreissenid infestation.") %>% kable_styling() %>% row_spec(0, bold = T, align = "c",extra_css = "border-bottom: 1px solid;") %>% row_spec(1, extra_css = "border-bottom: 1px solid;")

```

<br> <br>

```{r warning=FALSE, message=FALSE}

## Summarise number of infested and uninfested lakes in each risk category
overall_risk = thresholds %>% group_by(overall_risk,infestation) %>% summarise(count = n()) %>% pivot_wider(names_from = overall_risk, values_from = count)

overall_risk = overall_risk[,c(1,3,4,2)]

overall_risk$Low=overall_risk$Low %>% replace_na(0)

kable(overall_risk,align = "c",col.names = c("Infestation status","Low risk","Moderate risk", "High risk"), caption = "Number of Dreissenid infested or un-infested reservoirs categorized as low, moderate, or high risk for Dreissenid invasion based on factors including calcium concentration, mean summer temperature, pH, hardness, and distance to other infested water bodies.") %>% kable_styling() %>% row_spec(0, bold = T, align = "c",extra_css = "border-bottom: 1px solid;") %>% row_spec(2, extra_css = "border-bottom: 1px solid;")

```


<br>
<br>

```{r warning=FALSE, message=FALSE,fig.height=25,fig.width=45}

## Graph low, moderate, and high risk according to infested and uninfested

## Change data format to longer
overall_risk_long = overall_risk %>% pivot_longer(cols = c("Low","Moderate","High"),names_to = "Risk_level")

overall_risk_long$order = c(1,2,3,1,2,3)

overall_risk_long %>% ggplot(aes(fill = infestation,y = value,x = reorder(Risk_level,order))) + geom_bar(position = "dodge",stat = "identity") + labs(x = "Risk level", y = "Number of reservoirs") + theme(text = element_text(size = 80)) + scale_fill_manual(values = c("navyblue","orchid"),name = "Infestation status")

```

**Figure 5.** Number of USACE reservoirs falling into each overall risk category that are infested or un-infested with Dreissenids.

<br>
<br>
Based on our risk categories, approximately 46% of high risk reservoirs have already recorded Dreissenid presence. Approximately 16% of moderate risk reservoirs have also recorded Dreissenid presence. These reservoirs were ranked as moderate risk based on pH (n=13), pH and distance (n=1), or distance alone (n=4). One low risk reservoir, lake Ruthbun, is infested. Lake Rathbun is classified as low risk due to distance to nearest infestation. It is 128 km from the nearest Dreissenid observation. 

Most of the reservoirs limited by pH (e.g. moderate risk but still infested) were located in the Arkansas River drainage or in the Black-Warrior Tombigbee system in Alabama. One pH-limited and distance reservoir was located in Pennsylvania (Curwensville Lake). The five distance limited reservoirs (e.g. low or moderate risk but still infested) were in Iowa (Rothbun lake - low risk), North Dakota (Lake Ashtabula - moderate risk), Oklahoma (Waurika Lake - moderate risk), Kentucky (Lake Cumberland - moderate risk), Kansas (Wilson Lake - moderate risk), and Pennsylvania (Curwensville Lake - moderate risk). With the exception of Curwensville Lake (Pennsylvania), Oliver Lake (Alabama), and Rathbun Lake (Iowa), all invaded moderate risk reservoirs have established Dreissenid populations, with some having been invaded as early as the 1990s.* 

The fact that pH limited reservoirs are infested suggest that 1) more fine scale environmental data may be required to understand how intra-reservoir variation in environmental characteristics such as underlying geology could contribute to suitable conditions in reservoirs, or 2) that Dreissenids may be more tolerant of pH than expected. For the three remaining lakes where invasion status is unknown but positive Dreissenid records have occurred, it is possible that Dreissenids have been introduced to these reservoirs but have not been able to establish strong populations due to sub-optimal environmental conditions. For reservoirs with a low or moderate risk of invasion based on distance to the next nearest positive record, it is possible that Dreissenids were transported long distances by boaters given that few source populations were present nearby to fuel population expansion into these areas. Information on recreational boater movement is not systematically collected, and thus there is a need to further study how boaters move and how they affect the risk of infestation.



<br>
<br>

```{r warning=FALSE, message=FALSE}

## Summarise moderate risk lakes
## Load moderate reservoirs that are infested
mod_infest = thresholds %>% filter((pH_threshold == "Moderate" | dist_threshold_km == "Moderate" | dist_threshold_km == "Low") & infest_status == 1)


kable(mod_infest[,c(1,15:22)],col.names=c("Reservoir","Mean summer temp risk","pH risk","Hardness risk","Calcium risk","Distance risk","Overall risk", "Overall risk without distance","Infestation status"),align="l", caption = "Reservoirs with positive Dreissenid records despite being considered at moderate risk of Dreissenid invasion.") %>% 
  kable_styling(latex_options = "scale_down", font_size = 8)%>% 
  column_spec(2:ncol(thresholds[,c(1,15:22)]), width = "50px") %>% 
  scroll_box(width = "1000px", height = "500px")%>% 
  row_spec(0, bold = T, align="l",
           extra_css = "border-bottom: 1px solid;") %>% 
  kableExtra::landscape()

```
<br>
<br>


```{r warning=FALSE, message=FALSE}

## Create empty column to store which variable is of moderate risk
mod_infest$risk_var = NA

## Assign risk variables
mod_infest$risk_var[which(mod_infest$pH_threshold == "Moderate")] = "pH"
mod_infest$risk_var[which(mod_infest$dist_threshold_km %in% c("Moderate", "Low"))] = "Distance to nearest infestation"

res_mod_infest = res_raw %>% filter(name %in% mod_infest$name)

## Get centers of lakes
res_center = st_centroid(res_mod_infest) %>% 
  select(name)

res_center_mod = left_join(res_center, mod_infest, join_by(name))

## Plot data
ggplot() +
  geom_polygon(data = state_map, aes(x = long,y = lat,group = group), inherit.aes = F, 
     colour = 'black', fill = NA) +
  geom_sf(data = res_center_mod, aes(color = as.factor(risk_var))) +
  scale_color_manual(values = c("pH" = "navyblue", "Distance to nearest infestation" = "orchid"), 
                     labels = c("pH" = "pH", "Distance to nearest infestation" = "Distance to nearest infestation"),
                     name = "Dreissenid Presence") +
  labs(title = "Dreissenid presence in moderate and low risk USACE reservoirs") +
  theme_void()
```

<br>
**Figure 6.** Location of USACE reservoirs with moderate invasion risk based on pH or distance to nearest infestation that have positive Dreissenid occurrences according to NAS (Benson et al. 2024).

# Data analysis

Next, we used the data available on a national scale to try to better understand how different environmental and social factors may be related to Dreissenid presence in USACE reservoirs. We explored several analysis methods to investigate our questions, which are outlined below:

<br> <br>

## Correlation Matrices

Before we used any predictive models to evaluate the risk of dreissenid mussel invasion, we wanted to understand how correlated different variables are. When variables are correlated they may not be suited for certain types of modeling, like logistic regression. In the below figures, bigger, darker blue dots indicate that two variables are positively correlated, while bigger, darker red dots indicate a negative correlation.



```{r}
landuse <- ZQM_data %>% 
  select(perc_open_water_50mi, perc_dev_openspace_50mi: perc_wetland_50mi)

m = cor(landuse, use = "complete.obs")

corrplot(m, method = "circle", type = "upper",
         title = "correlation between land-use categories", 
         mar=c(0,0,2,0),
         diag=FALSE)
```
<br>
**Figure 7.** A correlation plot showing how correlated different land-use variables are. All urban land-use categories are positively correlated, while forested land is negatively correlated with herbaceous cover and crop cover.



```{r}
water_chem <- ZQM_data %>% 
  select(max_Ca, max_pH, max_hardness, c(perc_alluvial_25mi:perc_resid_volcanic_art_wat_25mi))

m = cor(water_chem, use = "complete.obs")

corrplot(m, method = "circle", type = "upper", 
         title = "correlation between water chemistry and geology variables",
         mar=c(0,0,2,0))
```

<br>
**Figure 8.** A correlation plot showing how correlated different water chemistry and geology variables are. There are no strong correlations among these variables.


```{r}
climate_cor <- ZQM_data %>% 
  select(winter_total_precip:fall_max_temp)

m = cor(climate_cor, use = "complete.obs")

corrplot(m, method = "circle", type = "upper", 
         title = "Correlation between climate variables",
         mar=c(0,0,2,0))
```
<br>
**Figure 9.** A correlation plot showing how correlated different climate variables are. Temperatures are all very correlated.


```{r}
ndci_cor <- ZQM_data %>% 
  select(mean_ndci_fall:max_ndci_winter)

m = cor(ndci_cor, use = "complete.obs")

corrplot(m, method = "circle", type = "upper", 
         title = "Correlation between seasonal NDCI values",
         mar=c(0,0,2,0))
```
<br>
**Figure 10.** A correlation plot showing how correlated seasonal NDCI variables are. Seasonal mean NDCI values are somewhat correlated with all NDCI variables.



```{r}
rec <- ZQM_data %>% 
  select(dist_to_infest_km, surface_area_km, mean_total_visits)

m = cor(rec, use = "complete.obs")

corrplot(m, method = "circle", type = "upper", 
         title = "Correlation between visits, surface area, and distance to infestation",
         mar=c(0,0,2,0))
```
<br>
**Figure 11.** A correlation plot showing how correlated surface area, distance to infestation, and visitation variables are. There are no strong correlations between the three variables.



```{r}
risks <- ZQM_data %>%  
  select(dist_to_infest_km, summer_mean_temp, max_Ca,
         max_pH, max_hardness)

m = cor(risks)

corrplot(m, method = "circle", type = "upper", 
         title = "Correlation between main risk variables",
         mar=c(0,0,2,0))
```
<br>
**Figure 12.** A correlation plot showing how correlated the variables that determine our risk categories are. There are no strong correlations among these variables

## Logistic regressions

We ran several exploratory logistic regression models using binary infested (1) versus not infested (0) as the outcome variable. We used different input variables in each logistic regression. Our goal was not to predict Dreissenid infestation, but rather to identify significant environmental predictors and the directionality of their influence.

We used the Akaike Information Criterion or AIC value to evaluate the quality of each model. The AIC value looks at the predictive power of the model as well as the number of inputs in each model. Generally, fewer inputs are better, because it reduces the chance of model over-fitting. There is no goal AIC value, rather comparatively lower AIC values indicate a better quality model compared to models with higher AIC values.

To assess the significance of each input we used the p value. The smaller the p value, the lower the chance that the input variable has no influence on the response variable. A p value of under 0.05 is indicated by a period, and anything smaller than that is indicated by one or more asterisks.

To evaluate the directionality of influence, we examined the coefficient value. The coefficient value indicates the change in log odds that the response variable will be 1 if the input variable increases by one unit. In our case, it indicates the log odds that a reservoir will be infested if the predictor variable is increased by one unit. Coefficients should only be evaluated if the model is of good quality and if the p value for the input value is very low.

<br> <br>

### Landcover

We ran a logistic regression with the percent of land dedicated to each land-use category within a 25 and 50 mile buffer of each reservoir as input variables. Data was from the NLCD.

First we ran the model with a 50 mile buffer for each land cover category.

Note that the model did not converge with percent perennial snow and ice included in the logistic regression.

Below is the model summary. The coefficient name (or input variable name) is in the first column on the left. The next column over, called `Estimate`, contains the coefficient value with tells you the directionality of influence that the coefficient has on the outcome variable. The column with the p value is on the far right. the AIC value is stated below the table output.

**Logistic Regression 1** 

```{r}
#some data cleaning
landcover_50  <- ZQM_data %>%
  select(infest_status, c(perc_open_water_50mi, perc_dev_openspace_50mi: perc_wetland_50mi)) %>% 
  mutate(infest_status = as.factor(infest_status))

#run the model
landcover_50_logit <- glm(infest_status ~ ., data = landcover_50, family = "binomial")

#print model summary
summary(landcover_50_logit)
```

Notes: In this model, there are no significant predictors of infestation.

We then ran the model with a 25 mile buffer. Note that the model also did not converge with percent open water or percent snow and ice variables included.

**Logistic Regression 2**

```{r}
#some data cleaning
landcover_25  <- ZQM_data %>%
  select(infest_status, c(perc_dev_openspace_25mi: perc_wetland_25mi)) %>% 
  mutate(infest_status = as.factor(infest_status))

#run the model
landcover_25_logit <- glm(infest_status ~ ., data = landcover_25, family = "binomial")

#print model summary
summary(landcover_25_logit)
```

Notes: When we ran the model with a 25 mile buffer, it showed barren land, forest cover, shrub cover, herbaceous cover, hay pasture cover, crop cover, and wetland cover to be significant predictors of infestation. Barren land has a slight positive influence on infestation, while all other significant variables are negatively associated with infestation. The model did not show any development categories to be significant. While this model does have a lower AIC value than the previous model, it still is not very low, indicating that this model is not performing particularly well.

In the next model, we aggregate all development classifications into a single category, again using the 25 mile buffer.

**Logistic Regression 3**

```{r}
#looking at what happens when development landcovers are summed
dev_sum <- ZQM_data %>% 
  mutate(dev_sum_25mi = perc_dev_openspace_25mi + perc_dev_lowintensity_25mi + perc_dev_medintensity_25mi + perc_dev_highintensity_25mi) %>% 
  select(dev_sum_25mi, infest_status, c(perc_barren_25mi:perc_wetland_25mi)) %>% 
  mutate(infest_status = as.factor(infest_status))

#run new model
dev_sum_25_logit <- glm(infest_status ~ ., data = dev_sum, family = "binomial")

#summarise new model
summary(dev_sum_25_logit)
```

Notes: The model showed all variables to be significant. Percent barren land has a postive relationship with infestation, while all other variables have a negative relationship with infestation. Of all land use logistic regressions, this one has the lowest AIC score. <br> <br>

### Water chemistry and geology

Next we ran a logistic regression with various water chemistry and geology characteristics as predictors. Note that many water chemistry variables are likely correlated, which is not ideal for logistic regression. This model is for exploratory purposes only. Below is the model summary.

**Logistic Regression 4**

```{r}
#looking at geology and water chemistry
water_chem <- ZQM_data %>% 
  select(infest_status, max_Ca, max_pH, max_hardness, c(perc_alluvial_25mi:perc_resid_volcanic_art_wat_25mi)) %>% 
  mutate(infest_status = as.factor(infest_status))

#run the model
water_chem_logit <- glm(infest_status ~ ., data = water_chem, family = "binomial")

#print summary
summary(water_chem_logit)
```

Notes: This model seems to indicate that pH and calcium content are statistically significant predictors of infestation. Increases in pH and calcium are associated with increases in the risk of infestation. This model has a comparatively higher AIC score, indicating poor model performance. <br>
<br>

### Climate

We also ran a logistic regression with various climate variables as predictors. Note that climate variables are likely all correlated, which is not ideal for logistic regression. This model is for exploratory purposes only.

**Logistic Regression 5**

```{r}
#looking at climate
climate <- ZQM_data %>% 
  select(infest_status, c(winter_total_precip:fall_max_temp)) %>% 
  mutate(infest_status = as.factor(infest_status))

#run the model
climate_logit <- glm(infest_status ~., data = climate, family = "binomial")

#print model summary
summary(climate_logit)
```

Notes: This model shows many temperature variables as being significant, and also summer and winter precipitation. The AIC value for this model is comparatively lower than models we examined previously.

We also ran a logistic regression with just total precipitation and summer mean temperature, to simplify the number of variables and eliminate highly correlated variables.

**Logistic Regression 6**

```{r}
#looking at just mean temps
mean_temp <- climate %>% 
  mutate(total_precip = winter_total_precip + spring_total_precip + summer_total_precip + fall_total_precip) %>% 
  select(infest_status, total_precip, summer_mean_temp) %>% 
  mutate(infest_status = as.factor(infest_status))

#run model with mean temps
mean_temp_logit <- glm(infest_status ~., data = mean_temp, family = "binomial")

#print model summary
summary(mean_temp_logit)
```

Notes: When looking at total precipitation and mean summer temperature, only mean summer temperature is significant. This model has a higher AIC value compared to the previous climate model. 

<br> <br>

### Size, recreation, and connectivity

In our next logistic regression, we looked at reservoir size (surface area), connectivity to other reservoirs, and the number of visitors.

**Logistic Regression 7**

```{r, warning=FALSE}
## Looking at proximity to water bodies, connection status, etc
connectivity <- ZQM_data %>% 
  select(infest_status, dist_to_infest_km, surface_area_km, connectivity, mean_total_visits) %>% 
  mutate(infest_status = as.factor(infest_status))

#set factor levels for connectivity
connectivity$connectivity <- factor(connectivity$connectivity, levels = c("None", "Dam", "Lock and Dam"))

#run model
connect_logit <- glm(infest_status ~., data = connectivity, family = "binomial")

#print model summary
summary(connect_logit)
```

Notes: distance to infestation is the most significant predictor, and surface area is also significant. Increasing distance has a negative relationship with infestation while increasing surface area has a slight positive relationship with infestation. Connectivity is also significant. Reservoirs with a lock and dam are more likely to be infested than those with just a dam or no connection. This model has the lowest AIC so far, indicating better predictive power when compared with the previous logistic regression models.

### Previously identified risk variables

Next we will run a logistic regression using all the variables we used to classify risk. These are variables that have been identified as potentially limiting to Dreissenid mussels in the literature. The variables are distance to nearest infestation, mean hardness, average calcium content, average pH, and mean summer temperature.

**Logistic Regression 8**

```{r, message=FALSE, warning=FALSE}
## Looking at proximity to water bodies, connection status, etc
risk_vars <- ZQM_data %>% 
  select(infest_status, dist_to_infest_km, summer_mean_temp, max_Ca,
         max_pH, max_hardness) %>% 
  mutate(infest_status = as.factor(infest_status))

#run model
risk_logit <- glm(infest_status ~., data = risk_vars, family = "binomial")

#print model summary
summary(risk_logit)
```

Notes: Distance to infestation is significant and negatively associated with infestation. Mean summer temperature is significant and positively associated with infestation. All other input variables are not significant. This model has a low AIC, but it is slightly higher than the size, recreation, and connectivity logistic model.

## Gradient Boosted Model

A gradient boosted model (GBM) is a flexible machine learning algorithm that is immune to issues caused by multicollinearity. It works by combining multiple weak models (think small decision trees) into one strong model.

In this instance, we split the data into training data to train the model and testing data to test the model. Since there is so little data, taking even a few observations away to later test the model may impact the model training.

We made the following modifications to the data to reduce the number of inputs.

-   We used percent land-use within 25 miles and dropped percent land-use within 50 miles. We also combined all development categories into one category.

-   We calculated total annual precipitation and used that and summer mean temperature from the climate data.

-   We used only summer mean NDCI

-   We used max calcium, max pH, and max hardness as water chemistry inputs

Below is a summary of the model, trained using the training data.

**Gradient Boosted Model 1**

```{r warning=FALSE,message=FALSE,fig.height=20,fig.width=20,attr.output='style="max-height: 500px;"'}
library(gbm) #for gradient boosting models
library(Metrics) #for RMSE calculation
library(rsample) #for splitting data into test and training

#prepare data for gradient boosted tree
boosted_data <- ZQM_data %>% 
  mutate(dev_sum_25mi = perc_dev_openspace_25mi + perc_dev_lowintensity_25mi + perc_dev_medintensity_25mi + perc_dev_highintensity_25mi) %>% 
  mutate(total_precip = winter_total_precip + spring_total_precip + summer_total_precip + fall_total_precip) %>% 
  select(dist_to_infest_km: num_connections,
         perc_open_water_25mi, dev_sum_25mi, perc_barren_25mi:perc_crops_25mi,
         mean_elev_m:perc_resid_volcanic_art_wat_25mi,
         max_hardness,
         total_precip,
         summer_mean_temp,
         mean_ndci_summer,
         mean_total_visits, 
         max_Ca,
         max_pH,
         infest_status) %>% 
  mutate(connectivity = as.factor(connectivity)) %>% 
  mutate(infest_status = as.numeric(infest_status))

#set factor levels for connectivity
boosted_data$connectivity <- factor(boosted_data$connectivity, levels = c("None", "Dam", "Lock and Dam"))

#define split parameters
boosted_data_split <- boosted_data %>% 
  initial_split(prop = 0.8, strata = infest_status)

#write split data to data frames
train_split <- training(boosted_data_split)
test_split <- testing(boosted_data_split)

#run model
infest_gbm = gbm(infest_status ~ ., 
                 distribution = "bernoulli",
                 data = train_split,
                 n.trees = 1000,
                 shrinkage = 0.01,
                 interaction.depth = 4)
#print model
infest_gbm
```

Below is a list of the most influential variables, according to the gradient boosted model. Variables with a higher `rel.inf`are more influential in the model outcome. Note that the influence value is meant to be interpreted relative to other influence values. Even though predictions generated using GBM models are not affected by multicollinearity, if two variables are highly correlated, the influence will be split between them.

```{r warning=FALSE,message=FALSE,fig.height=20,fig.width=20,attr.output='style="max-height: 500px;"'}
#the model summary
summary(infest_gbm, plotit = F)
```

Note: Distance to infestation is vastly more influential than other predictors.

It is also possible to see the general relationship between the predictor variables and the outcome variable. Below are figures showing the relationship between infestation on the Y axis (recall 0 indicates not infested and 1 indicates infested) and the predictor variable on the X axis. Note the different axis values between plots.

```{r}
#plot some rough graphs showing relationship between infestation and key vars
plot(infest_gbm,i="dist_to_infest_km", type = "response", xlab = "Distance to nearest infestation (km)")
```

**Figure 13.** There is a negative relationship between infestation and the distance to the nearest infested body of water. Infestation is much more likely when other infestations are close.

```{r}
plot(infest_gbm,i="max_Ca", type = "response", xlab = "Maximum calcium concentration (mg/L)") 
```

**Figure 14.** There is a positive relationship between observed maximum calcium levels and infestation status.

```{r}
plot(infest_gbm,i="surface_area_km", type = "response", xlab = "Surface area (km^2)") 
```

**Figure 15.** There is a positive relationship between infestation and the size of the reservoir. Larger reservoirs are more likely to be infested.

```{r}
plot(infest_gbm,i="summer_mean_temp", type = "response", xlab = "Mean summer temperature (C)") 
```

**Figure 16.** There is a positive relationship between summer mean temperatures and infestation status.

<br> <br>

Next we use the model to generate predictions. We will then create a confusion matrix and calculate RMSE. A confusion matrix shows the number of true negatives (top left value), false negatives (top right), false positives (bottom left), and true positives (bottom right). RMSE stands for Root Mean Squared Error. A smaller RMSE indicates the model is more accurate.

Below is a confusion matrix for the training data.

```{r, message=FALSE}
#generating predictions for training data
train_preds <- predict.gbm(infest_gbm, newdata = train_split, type="response")

#converting to 0,1 outcome
train_pred_class <- ifelse(train_preds > 0.5, 1, 0)

#creating confusion matrix
confusionMatrix(as.factor(train_pred_class), 
                as.factor(train_split$infest_status),
                positive = '1')
```

Below is the RMSE for the training data

```{r, message=FALSE}
#create predictions
predictions_training <- predict(infest_gbm, newdata = train_split, type = "response")

#calculate RMSE for training data
Metrics::rmse(predictions_training, train_split$infest_status)
```

Below is a confusion matrix for the test data.

```{r, message=FALSE}
#testing model
test_preds <- predict.gbm(infest_gbm, newdata = test_split, type="response")

test_pred_class <- ifelse(test_preds > 0.5, 1, 0)

confusionMatrix(as.factor(test_pred_class), 
                as.factor(test_split$infest_status),
                positive = '1')
```

Below is RMSE for the test data.

```{r, message=FALSE}
#create predictions
predictions_test <- predict.gbm(infest_gbm, newdata = test_split, type = "response")

#calculate RMSE for training data
Metrics::rmse(predictions_test, test_split$infest_status)
```

The shows some signs of overfitting. It "predicts" infestation with perfect accuracy when given the training data, but it is less accurate when predicting infestation with new data. Still, the model is reasonably effective and may be further improved with model tuning.

<br> <br>

## Random forest analysis

Random forest classification is a type of machine learning that functions similarly to classification and regression tree analysis (CART). Random forest analysis does not assume linearity, normality, or homoscedasticity and is less sensitive to spatial autocorrelation and multicollinearity.

Random forest classification works by generating a series of bootstrapped trees that have low correlation with one another and averaging the results of these individual trees across a "forest" of many trees to prevent overfitting. Individual trees are created by randomly selecting a subset of all possible variables and using them to build and test a classification scheme using randomly selected training (64%) and test data (36%). Since each tree uses a random subset of variables and different training and test data, they should be relatively different from one another.

We can evaluate the performance of the random forest classification by obtaining an estimate of out-of-bag (OOB) error, which describes the overall percentage of incorrectly categorized data (in this case presence versus absence), averaged across trees.

We used the 'randomForest' package in R to run this analysis (Liaw and Wiener, 2002).

We obtained several outputs from the random forest classification, including:


1)  Accuracy: overall accuracy of classification (average % of time random forest correctly classifies records)
2)  Confidence interval: The 95% confidence interval for the accuracy rate
3)  No information rate: The accuracy of the model if we were to assign all reservoirs a value of zero without running a classification
4)  P-value (Acc > NIR): Indicates whether your model accuracy is significantly higher than your no information rate, which is an indication that your model provides valuable information
5)  McNemar's test p-value: This test statistic serves to test whether the counts of false positives in the model are significantly different from the counts of false negatives.If the p-value of the test is significant, than we can say relatively confidently that the model has a different proportion of false positives and false negatives. McNemar's test compares the difference in the relative proportion of error between the two rather than the difference in error itself
6)  Sensitivity: The probability that an infested reservoir will be correctly classified as infested
7)  Specificity: The probability that an uninfested reservoir will be correctly classified as uninfested
8)  Pos pred value: The proportion of true positives captured by the total number of predicted positives
9)  Neg pred value: The proportion of true negatives captured by the total number of predicted negatives
10) Prevalence: The rate of all true positives in the whole population (The actual prevalence of infestations across reservoirs, regardless of classification)
11) Detection rate: The rate of detected true positives in the whole population (how many infested reservoirs are categorized as infested)
12) Detection prevalence: The rate of predicted positives in the whole population (how many reservoirs are predicted to be infested based on the classification)
13) Balanced accuracy: The average of sensitivity and specificity scores
14) Positive class: The class identified as indicating a 'positive' record (i.e., Dreissenid presence)
15) Importance: The average decrease in model accuracy if a given variable were dropped from the analysis

To run our random forest classification, we created 1000 trees using the default settings, including:

mtry: number of variables randomly sampled as candidates at each split (sqrt(p) by default, where p is the number of variables).

nodesize: minimum size of terminal nodes (1 by default)

To account for highly correlated variables, which can affect variable importance scores in the random forest model, we identified any variables with a correlation coefficient higher than 0.8 and retained only one variable from each of these groups. For LULC, we retained data for 25 mile buffers over 50 mile buffers given their better performance in the logistic regressions. For water quality data, we retained maximum values over average values because they performed better when classifying reservoir invasion risk. For developed land cover and seasonal precipitation, we summed categories based on logistic regression performance.

### Random forest with test and training datasets

Below is a random forest model trained with the same training data given to the gradient boosted model. First the variable importance is displayed:

**Random Forest Model 1**

```{r, fig.height = 15,fig.width=15}
## Random forest with training and test datasets


## Train the model

infest_rf = randomForest(as.factor(infest_status) ~ ., #writing the formula
                          data = train_split, #specifying training data to be used
                          mtry = sqrt(length(train_split)-1), #setting number of variables to randomly sample per each split
                          ntree= 1000, #setting number of trees
                          na.action = na.omit, #specifying what to do with NAs
                          importance = TRUE #specifying importance of variables should be assessed
                          )

## Change colnames for better x-axis labels in importance plot
colnames(infest_rf$importance) = c("0", "1", "Mean decrease in accuracy", "Mean decrease in Gini impurity")

## Check variable importance
varImpPlot(infest_rf,sort = T,n.var = (length(train_split) - 1),main = "Variable importance plot")

```
<br>
**Figure 17.** Variable importance plot for variables in the random forest model. 'Mean decrease in accuracy' indicates the decrease in accuracy of the model should a given variable be randomly permuted (i.e., its effect removed). 'Mean decrease in Gini impurity' is a measure of the average gain in purity of splits for a given variable.

Then we will create a confusion matrix for the training data and test its performance for classification:

```{r attr.output='style="max-height: 500px;"'}
#training confusion matrix
p_train <- predict(infest_rf, newdata = train_split)
confusionMatrix(p_train, as.factor(train_split$infest_status),positive = '1')
```

Above, we see that RF model is 100% accurate and the confusion matrix for the training data indicates that all Dreissenid presences and absences are correctly classified. The accuracy rate is statistically significantly higher than the no information rate, and the prevalence and detection rates mirror that of the actual population (~24% of reservoirs have positive records). Next, we will test our model with the testing dataset:

```{r attr.output='style="max-height: 500px;"'}
#test confusion matrix
p_test <- predict(infest_rf, newdata = test_split)
confusionMatrix(p_test, as.factor(test_split$infest_status),positive = '1')

#No RMSE for categorical outcomes in RF

```

<br>
Here, our RF model correctly classifies reservoirs based on Dreissenid presence approximately 82% of the time, although the balanced accuracy is lower (around 74%) because the model's sensitivity is poor. In other words, the model is not very good at accurately recognizing when Dreissenids are present, even though it is fairly good at predicting when Dreissenids are absent (as indicated by the high specificity rate). Furthermore, the accuracy rate is not significantly better than the no information rate, indicating that we could just assign all reservoirs as "absent" and still perform about as well as our model does now. The prevalence of Dreissenids in the test dataset is similar to the whole dataset, but the detection rate and detection prevalence are lower than the true prevalence. Our model may be limited by the "noise" of having so many variables included in it, so we decided to try reducing the number of variables by looking at only the 10 most important variables according to the mean decrease in accuracy metric.
<br>
<br>

### Random forest with reduced variables

**Random Forest Model 2**

```{r, fig.width=10}
## Random forest with training and test datasets

train_split_red = train_split %>% select(c(dist_to_infest_km,max_Ca,summer_mean_temp,
                                           surface_area_km,total_precip,perc_shrubscrub_25mi,
                                           max_pH,perc_forest_25mi,perc_open_water_25mi,
                                           perc_crops_25mi,infest_status))

test_split_red = test_split %>% select(c(dist_to_infest_km,max_Ca,summer_mean_temp,
                                           surface_area_km,total_precip,perc_shrubscrub_25mi,
                                           max_pH,perc_forest_25mi,perc_open_water_25mi,
                                           perc_crops_25mi,infest_status))

## Train the model
rf_ten_vars = randomForest(as.factor(infest_status) ~ ., #writing the formula
                          data = train_split_red, #specifying training data to be used
                          mtry = sqrt(length(train_split_red)-1), #setting number of variables to randomly sample per each split
                          ntree= 1000, #setting number of trees
                          na.action = na.omit, #specifying what to do with NAs
                          importance = TRUE #specifying importance of variables should be assessed
                          )

## Change colnames for better x-axis labels in importance plot
colnames(rf_ten_vars$importance) = c("0", "1", "Mean decrease in accuracy", "Mean decrease in Gini impurity")

## Check variable importance
varImpPlot(rf_ten_vars,sort = T,main = "Variable importance plot")
```
<br>
**Figure 18.** Variable importance plot for the top 10 variables in the random forest model. 'Mean decrease in accuracy' indicates the decrease in accuracy of the model should a given variable be randomly permuted (i.e., its effect removed). 'Mean decrease in Gini impurity' is a measure of the average gain in purity of splits for a given variable.
<br>
<br>
Next, we will create a confusion matrix for the training data.

```{r attr.output='style="max-height: 500px;"'}
#training confusion matrix
p_train <- predict(rf_ten_vars, newdata = train_split_red)
confusionMatrix(p_train, as.factor(train_split_red$infest_status),positive = '1')
```
Similarly to our RF model with all variables, this RF model is 100% accurate for the training data. Next, we'll see how it performs with the test data:

```{r attr.output='style="max-height: 500px;"'}
#test confusion matrix
p_test <- predict(rf_ten_vars, newdata = test_split_red)
confusionMatrix(p_test, as.factor(test_split_red$infest_status),positive = '1')

#No RMSE for categorical outcomes in RF

```
Removing all but the 10 most influential variables actually decreases the performance of the model slightly, and the model accuracy is still not significantly better than the no information rate. We will also try a random forest model containing just the variables used in our risk assessment to see if that improves the performance.

<br>
<br>

### Random forest with risk variables

Next, we will try the random forest using only the variables identified for risk thresholds to see if we can successfully classify reservoirs based on only a few environmental variables. Below, we have the variable importance plot:

**Random Forest Model 3**

```{r fig.width=10}
## Random forest with training and test datasets

train_split_risk = train_split %>% select(c(dist_to_infest_km,max_Ca,max_pH,max_hardness,summer_mean_temp,infest_status))

test_split_risk = test_split %>% select(c(dist_to_infest_km,max_Ca,max_pH,max_hardness,summer_mean_temp,infest_status))

## Train the model
rf_risk_vars = randomForest(as.factor(infest_status) ~ ., #writing the formula
                          data = train_split_risk, #specifying training data to be used
                          mtry = sqrt(length(train_split_risk)-1), #setting number of variables to randomly sample per each split
                          ntree= 1000, #setting number of trees
                          na.action = na.omit, #specifying what to do with NAs
                          importance = TRUE #specifying importance of variables should be assessed
                          )

## Change colnames for better x-axis labels in importance plot
colnames(rf_risk_vars$importance) = c("0", "1", "Mean decrease in accuracy", "Mean decrease in Gini impurity")

## Check variable importance
varImpPlot(rf_risk_vars,sort = T,main = "Variable importance plot")
```
<br>
**Figure 19.** Variable importance plot for risk variables in the random forest model. 'Mean decrease in accuracy' indicates the decrease in accuracy of the model should a given variable be randomly permuted (i.e., its effect removed). 'Mean decrease in Gini impurity' is a measure of the average gain in purity of splits for a given variable.
<br>
<br>
Next, we will create a confusion matrix for the training data.

```{r attr.output='style="max-height: 500px;"'}
#training confusion matrix
p_train <- predict(rf_risk_vars, newdata = train_split_risk)
confusionMatrix(p_train, as.factor(train_split_risk$infest_status),positive = '1')
```

Similarly to our RF model with all variables, this RF model is 100% accurate for the training data. Next, we'll see how it performs with the test data:

```{r attr.output='style="max-height: 500px;"'}
#test confusion matrix
p_test <- predict(rf_risk_vars, newdata = test_split_risk)
confusionMatrix(p_test, as.factor(test_split_risk$infest_status),positive = '1')

#No RMSE for categorical outcomes in RF

```

Here, we can see that reducing the number of variables in our model resulted in little decrease in model accuracy (~82%) and the balanced accuracy (~74%) of our RF model. However, the model's sensitivity is still relatively poor and our accuracy is not significantly better than the no information rate. One factor that could be contributing to this is that the average temperatures of the reservoirs may not be particularly useful for distinguishing between reservoirs that are at risk of invasion. This is pretty clear in our risk assessment, because only a single reservoir is classified below high risk based on our thresholds. Hence, we decided to also try a Random Forest model without mean summer temperature.

### Random forest with reduced variables no temperature

Since we know we have limited information about duration of temperature stressors, we will also try the random forest using only the variables identified for risk thresholds, but excluding temperature risk thresholds.

**Random Forest Model 4**

```{r fig.width=10}
## Random forest with training and test datasets

train_split_red_temp = train_split %>% select(c(dist_to_infest_km,max_Ca,max_pH,max_hardness,infest_status))

test_split_red_temp = test_split %>% select(c(dist_to_infest_km,max_Ca,max_pH,max_hardness,infest_status))

## Train the model
rf_risk_vars_temp = randomForest(as.factor(infest_status) ~ ., #writing the formula
                          data = train_split_red_temp, #specifying training data to be used
                          mtry = sqrt(length(train_split_red_temp)-1), #setting number of variables to randomly sample per each split
                          ntree= 500, #setting number of trees
                          na.action = na.omit, #specifying what to do with NAs
                          importance = TRUE #specifying importance of variables should be assessed
                          )

## Change colnames for better x-axis labels in importance plot
colnames(rf_risk_vars_temp$importance) = c("0", "1", "Mean decrease in accuracy", "Mean decrease in Gini impurity")


## Check variable importance
varImpPlot(rf_risk_vars_temp,sort = T,main = "Variable importance plot")

```
<br>
**Figure 20.** Variable importance plot for risk variables in the random forest model, excluding mean summer temperature. 'Mean decrease in accuracy' indicates the decrease in accuracy of the model should a given variable be randomly permuted (i.e., its effect removed). 'Mean decrease in Gini impurity' is a measure of the average gain in purity of splits for a given variable.
<br> <br> Then we will create a confusion matrix for the training data.

```{r attr.output='style="max-height: 500px;"'}
#training confusion matrix
p_train <- predict(rf_risk_vars_temp, newdata = train_split_red_temp)
confusionMatrix(p_train, as.factor(train_split_red_temp$infest_status),positive = '1')
```

Like all the other models, the RF model performs perfectly on the training data.

```{r attr.output='style="max-height: 500px;"'}
#test confusion matrix
p_test <- predict(rf_risk_vars_temp, newdata = test_split_red_temp)
confusionMatrix(p_test, as.factor(test_split_red_temp$infest_status),positive = '1')

#No RMSE for categorical outcomes in RF

```

When we apply the new RF model to the test data, our accuracy improves to around 86%, with a balanced accuracy around 77%. Although the model's sensitivity is still relatively low, here we see that our RF model is significantly better than the no information rate, meaning it contains information that is actually useful.

<br>
<br>

# Conclusions

Based on our analysis, the most limiting factor related to Dreissenid presence in USACE reservoirs seems to be the distance to the closest current Dreissenid infestation. This is particularly concerning because it suggests that Dreissenid spread may be more limited by dispersal than by environmental conditions, meaning that efforts to control the spread of Dreissenids are tantamount for controlling continued expansion of populations in the U.S. Beyond distance, maximum calcium was consistently an important variable, which aligns with past research on environmental requirements of Dreissenids. Our risk analysis suggests that just over 50% of USACE reservoirs may be considered high risk for Dreissenid infestation, with an additional 21% considered moderate risk. Efforts to prevent the continued spread of Dreissenids could benefit from additional focus on preventing transport of veligers or mussels between nearby lakes via recreational activities. Furthermore, collection of more fine scale water quality data could help refine our risk estimates, particularly for lakes that exhibit higher intra-reservoir variation in waer quality due to geology or other factors.


<br> <br> <br>

# References


Benson, A. J., Raikow, D., Larson, J., Fusaro, A., Bogdanoff, A. K., and A. Elgin. (2024). *Dreissena polymorpha* (Pallas, 1771): U.S. Geological Survey, Nonindigenous Aquatic Species Database, Gainesville, Florida. https://nas.er.usgs.gov/queries/FactSheet.aspx?speciesID=5, Revision Date: 12/21/2023, Access Date: 7/29/2024

Brownlee, J. (2019). How to calculate McNemar's test to compare two machine learning classifiers. https://machinelearningmastery.com/mcnemars-test-for-machine-learning/. Access Date: 12/3/2024 

Brownlee, J. (2019). Feature selection with the Caret R Package. https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/. Access Date: 12/03/2024.

Cohen, A. N. (2005). A review of Zebra Mussels' environmental requirements: a report for the California Department of Water Resources. San Francisco Estuary Institute, Oakland, California. 33 pp.

Cohen, A. N., and A. Weinstein. (1998). The potential distribution and abundance of Zebra Mussels in California. San Francisco Estuary Institute, Richmond, California. 

Creamer, D. A., Rogosch, J. S., Patio, R., & McGarrity, M. E. (2025). Identifying lakes critical to the westward spread and establishment of zebra mussels. Biological Conservation, 302, 110931. https://doi.org/10.1016/j.biocon.2024.110931

Doll, B. (1997). Zebra Mussel colonization: North Carolina's risks. Sea Grant North Carolina, Raleigh, North Carolina (UNC SG-97-01).

Kislik, C., Dronova, I., Grantham, T. E., Kelly, M. (2022) Mapping algal bloom dynamics in small reservoirs using Sentinel-2 imagery in Google Earth Engine. Ecological Indicators, Volume 140. https://doi.org/10.1016/j.ecolind.2022.109041.

Liaw A, and M. Wiener. (2002). Classification and regression by Random Forest. R News. 2(3):1822. Available
from: https://CRAN.R-project.org/doc/Rnews/.

Mishra, Sachidananda & Mishra, Deepak. (2012). Normalized difference chlorophyll index: A novel model for remote estimation of chlorophyll-a concentration in turbid productive waters. Remote Sensing of Environment. 117. 394-406. 10.1016/j.rse.2011.10.016. 

Sorba, E. A., and D. A. Williamson. (1997). Zebra Mussel colonization potential in Manitoba, Canada. Water Quality Management Section, Manitoba Environment, Report No. 97-07.

White, J. D., S. K. Hamilton, and O. Sarnelle. (2015). Heat-induced mass mortality of invasive Zebra Mussels (Dreissena polymorpha) at sublethal temperatures. Canadian Journal of Fisheries and Aquatic Sciences. 72(8):1221-1229. https://doi.org/10.1139/cjfas-2015-0064.

